import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sn
import os
import tensorflow as tf
from sklearn.metrics import confusion_matrix ,
classification_report

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input , Dense ,
Conv2D , MaxPooling2D , Flatten , Activation , Dropout ,
Lambda
from tensorflow.keras.optimizers import Adadelta
from tensorflow.keras.preprocessing.image import
ImageDataGenerator
from tensorflow.keras.callbacks import
ReduceLROnPlateau , ModelCheckpoint
##############################################
learning_rate = 0.1 # initial learning rate
min_learning_rate = 0.00001 # once the learning rate
reaches this value , do not decrease it further
learning_rate_reduction_factor = 0.5 # the factor
used when reducing the learning rate ->
learning_rate *= learning_rate_reduction_factor
patience = 3 # how many epochs to wait before
reducing the learning rate when the loss plateaus
verbose = 1 # controls the amount of logging done
during training and testing: 0 - none , 1 - reports
metrics after each batch , 2 - reports metrics after
each epoch
image_size = (100 , 100) # width and height of the
used images
input_shape = (100 , 100, 3) # the expected input
shape for the trained models; since the images in
the Fruit -360 are 100 x 100 RGB images , this is the
required input shape
use_label_file = False # set this to true if you want
load the label names from a file; uses the
label_file defined below; the file should contain
the names of the used labels , each label on a
separate line
label_file = ’labels.txt ’
base_dir = ’../.. ’ # relative path to the Fruit -
Images -Dataset folder
test_dir = os.path.join(base_dir , ’Test ’)
train_dir = os.path.join(base_dir , ’Training ’)
output_dir = ’output_files ’ # root folder in which to
save the the output files; the files will be under
output_files/model_name
##############################################
if not os.path.exists(output_dir):
	os.makedirs(output_dir)
# if we want to train the network for a subset of the
fruit classes instead of all, we can set the
use_label_file to true and place in the label_file
the classes we want to train for, one per line
if use_label_file:
 with open(label_file , "r") as f:
 labels = [x.strip() for x in f.readlines()]
 else:
 labels = os.listdir(train_dir)
 num_classes = len(labels)
# create 2 charts , one for accuracy , one for loss , to
show the evolution of these two metrics during the
training process
def plot_model_history(model_history , out_path=""):
fig, axs = plt.subplots(1, 2, figsize=(15 , 5))
# summarize history for accuracy
axs[0].plot(range(1, len(model_history.history[’
acc ’]) + 1), model_history.history[’acc ’])
axs[0].set_title(’Model Accuracy ’)
axs[0].set_ylabel(’Accuracy ’)
axs[0].set_xlabel(’Epoch ’)
axs[0].set_xticks(np.arange(1, len(model_history.
history[’acc ’]) + 1), len(model_history.history
[’acc ’]))
53 axs[0].legend([’train ’], loc=’best ’)
54 # summarize history for loss
30
55 axs[1].plot(range(1, len(model_history.history[’
loss ’]) + 1), model_history.history[’loss ’])
56 axs[1].set_title(’Model Loss ’)
57 axs[1].set_ylabel(’Loss ’)
58 axs[1].set_xlabel(’Epoch ’)
59 axs[1].set_xticks(np.arange(1, len(model_history.
history[’loss ’]) + 1), len(model_history.
history[’loss ’]))
60 axs[1].legend([’train ’], loc=’best ’)
61 # save the graph in a file called "acc.png" to be
available for later; the model_name is provided
when creating and training a model
62 if out_path:
63 plt.savefig(out_path + "/acc.png")
64 plt.show()
65
66
67 # create a confusion matrix to visually represent
incorrectly classified images
68 def plot_confusion_matrix(y_true , y_pred , classes ,
out_path=""):
69 cm = confusion_matrix(y_true , y_pred)
70 df_cm = pd.DataFrame(cm, index=[i for i in classes
], columns=[i for i in classes])
71 plt.figure(figsize=(40 , 40))
72 ax = sn.heatmap(df_cm , annot=True , square=True ,
fmt="d", linewidths=.2, cbar_kws={"shrink":
0.8})
73 if out_path:
74 plt.savefig(out_path + "/ confusion_matrix .png"
) # as in the plot_model_history , the
matrix is saved in a file called "
model_name_confusion_matrix.png"
75 return ax
76
77
78 # Randomly changes hue and saturation of the image to
simulate variable lighting conditions
31
79 def augment_image(x):
80 x = tf.image.random_saturation(x, 0.9, 1.2)
81 x = tf.image.random_hue(x, 0.02)
82 return x
83
84
85 # given the train and test folder paths and a
validation to test ratio , this method creates three
generators
86 # - the training generator uses (100 -
validation_percent) of images from the train set
87 # it applies random horizontal and vertical flips
for data augmentation and generates batches
randomly
88 # - the validation generator uses the remaining
validation_percent of images from the train set
89 # does not generate random batches , as the model is
not trained on this data
90 # the accuracy and loss are monitored using the
validation data so that the learning rate can be
updated if the model hits a local optimum
91 # - the test generator uses the test set without any
form of augmentation
92 # once the training process is done , the final
values of accuracy and loss are calculated on this
set
93 def build_data_generators(train_folder , test_folder ,
labels=None , image_size=(100 , 100) , batch_size=50):
94 train_datagen = ImageDataGenerator(
width_shift_range=0.0 , height_shift_range=0.0 ,
zoom_range=0.0 , horizontal_flip=True ,
vertical_flip=True , preprocessing_function=
augment_image) # augmentation is done only on
the train set (and optionally validation)
95
96 test_datagen = ImageDataGenerator()
97
98 train_gen = train_datagen.flow_from_directory(
32
train_folder , target_size=image_size ,
class_mode=’sparse ’, batch_size=batch_size ,
shuffle=True , subset=’training ’, classes=labels
)
99 test_gen = test_datagen.flow_from_directory(
test_folder , target_size=image_size , class_mode
=’sparse ’, batch_size=batch_size , shuffle=False
, subset=None , classes=labels)
100 return train_gen , test_gen
101
102
103 # Create a custom layer that converts the original
image from
104 # RGB to HSV and grayscale and concatenates the
results
105 # forming in input of size 100 x 100 x 4
106 def convert_to_hsv_and_grayscale(x):
107 hsv = tf.image.rgb_to_hsv(x)
108 gray = tf.image.rgb_to_grayscale(x)
109 rez = tf.concat([hsv, gray], axis=-1)
110 return rez
111
112
113 def network(input_shape , num_classes):
114 img_input = Input(shape=input_shape , name=’data ’)
115 x = Lambda(convert_to_hsv_and_grayscale)(img_input
)
116 x = Conv2D(16, (5, 5), strides=(1, 1), padding=’
same ’, name=’conv1 ’)(x)
117 x = Activation(’relu ’, name=’conv1_relu ’)(x)
118 x = MaxPooling2D((2, 2), strides=(2, 2), padding=’
valid ’, name=’pool1 ’)(x)
119 x = Conv2D(32, (5, 5), strides=(1, 1), padding=’
same ’, name=’conv2 ’)(x)
120 x = Activation(’relu ’, name=’conv2_relu ’)(x)
121 x = MaxPooling2D((2, 2), strides=(2, 2), padding=’
valid ’, name=’pool2 ’)(x)
122 x = Conv2D(64, (5, 5), strides=(1, 1), padding=’
33
same ’, name=’conv3 ’)(x)
123 x = Activation(’relu ’, name=’conv3_relu ’)(x)
124 x = MaxPooling2D((2, 2), strides=(2, 2), padding=’
valid ’, name=’pool3 ’)(x)
125 x = Conv2D(128 , (5, 5), strides=(1, 1), padding=’
same ’, name=’conv4 ’)(x)
126 x = Activation(’relu ’, name=’conv4_relu ’)(x)
127 x = MaxPooling2D((2, 2), strides=(2, 2), padding=’
valid ’, name=’pool4 ’)(x)
128 x = Flatten()(x)
129 x = Dense(1024 , activation=’relu ’, name=’fcl1 ’)(x)
130 x = Dropout(0.2)(x)
131 x = Dense(256 , activation=’relu ’, name=’fcl2 ’)(x)
132 x = Dropout(0.2)(x)
133 out = Dense(num_classes , activation=’softmax ’,
name=’predictions ’)(x)
134 rez = Model(inputs=img_input , outputs=out)
135 return rez
136
137
138 # this method performs all the steps from data setup ,
training and testing the model and plotting the
results
139 # the model is any trainable model; the input shape
and output number of classes is dependant on the
dataset used , in this case the input is 100x100 RGB
images and the output is a softmax layer with 118
probabilities
140 # the name is used to save the classification report
containing the f1 score of the model , the plots
showing the loss and accuracy and the confusion
matrix
141 # the batch size is used to determine the number of
images passed through the network at once , the
number of steps per epochs is derived from this as
(total number of images in set // batch size) + 1
142 def train_and_evaluate_model(model , name="", epochs
=25, batch_size=50, verbose=verbose , useCkpt=False)
34
:
143 print(model.summary())
144 model_out_dir = os.path.join(output_dir , name)
145 if not os.path.exists(model_out_dir):
146 os.makedirs(model_out_dir)
147 if useCkpt:
148 model.load_weights(model_out_dir + "/model.h5"
)
149
150 trainGen , testGen = build_data_generators(
train_dir , test_dir , labels=labels , image_size=
image_size , batch_size=batch_size)
151 optimizer = Adadelta(lr=learning_rate)
152 model.compile(optimizer=optimizer , loss="
sparse_categorical_crossentropy ", metrics=["acc
"])
153 learning_rate_reduction = ReduceLROnPlateau(
monitor=’loss ’, patience=patience , verbose=
verbose ,
154 factor
=
learning_rate_reduction_,
min_lr
=
min_learning_rate
)
155 save_model = ModelCheckpoint(filepath=
model_out_dir + "/model.h5", monitor=’loss ’,
verbose=verbose ,
156 save_best_only=True ,
save_weights_only=
False , mode=’min ’,
save_freq=’epoch ’
)
157
158 history = model.fit(trainGen , epochs=epochs ,
steps_per_epoch=(trainGen.n // batch_size) + 1,
35
verbose=verbose , callbacks=[
learning_rate_reduction , save_model])
159
160 model.load_weights(model_out_dir + "/model.h5")
161
162 trainGen.reset()
163 loss_t , accuracy_t = model.evaluate(trainGen ,
steps=(trainGen.n // batch_size) + 1, verbose=
verbose)
164 loss , accuracy = model.evaluate(testGen , steps=(
testGen.n // batch_size) + 1, verbose=verbose)
165 print("Train: accuracy = %f ; loss_v = %f" % (
accuracy_t , loss_t))
166 print("Test: accuracy = %f ; loss_v = %f" % (
accuracy , loss))
167 plot_model_history(history , out_path=model_out_dir
)
168 testGen.reset()
169 y_pred = model.predict(testGen , steps=(testGen.n
// batch_size) + 1, verbose=verbose)
170 y_true = testGen.classes[testGen.index_array]
171 plot_confusion_matrix(y_true , y_pred.argmax(axis
=-1), labels , out_path=model_out_dir)
172 class_report = classification_report(y_true ,
y_pred.argmax(axis=-1), target_names=labels)
173
174 with open(model_out_dir + "/ classification_report .
txt", "w") as text_file:
175 text_file.write("%s" % class_report)
176
177
178 print(labels)
179 print(num_classes)
180 model = network(input_shape=input_shape , num_classes=
num_classes)
181 train_and_evaluate_model(model , name="fruit -360 model"
)
